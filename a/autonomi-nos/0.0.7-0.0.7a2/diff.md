# Comparing `tmp/autonomi_nos-0.0.7-py3-none-any.whl.zip` & `tmp/autonomi_nos-0.0.7a2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,69 +1,68 @@
-Zip file size: 91005 bytes, number of entries: 67
--rw-rw-r--  2.0 unx      164 b- defN 23-Jul-20 21:11 nos/__init__.py
--rw-rw-r--  2.0 unx      637 b- defN 23-Jul-18 05:56 nos/constants.py
+Zip file size: 84104 bytes, number of entries: 66
+-rw-rw-r--  2.0 unx      164 b- defN 23-Jul-12 06:39 nos/__init__.py
+-rw-rw-r--  2.0 unx      635 b- defN 23-Jul-14 21:48 nos/constants.py
 -rw-rw-r--  2.0 unx       93 b- defN 23-Jun-16 01:40 nos/exceptions.py
 -rw-rw-r--  2.0 unx      940 b- defN 23-May-09 22:15 nos/logging.py
--rw-rw-r--  2.0 unx     2897 b- defN 23-Jul-15 23:18 nos/protoc.py
--rw-rw-r--  2.0 unx       22 b- defN 23-Jul-20 18:52 nos/version.py
--rw-rw-r--  2.0 unx    11371 b- defN 23-Jul-15 01:04 nos/cli/benchmark.py
--rw-rw-r--  2.0 unx      540 b- defN 23-Jul-15 01:04 nos/cli/cli.py
--rw-rw-r--  2.0 unx     4222 b- defN 23-Jul-15 01:04 nos/cli/docker.py
+-rw-rw-r--  2.0 unx     2778 b- defN 23-May-19 22:25 nos/protoc.py
+-rw-rw-r--  2.0 unx       24 b- defN 23-Jul-13 18:07 nos/version.py
+-rw-rw-r--  2.0 unx    11371 b- defN 23-Jul-13 16:56 nos/cli/benchmark.py
+-rw-rw-r--  2.0 unx      540 b- defN 23-Jul-13 18:49 nos/cli/cli.py
+-rw-rw-r--  2.0 unx     4222 b- defN 23-Jul-13 19:08 nos/cli/docker.py
 -rw-rw-r--  2.0 unx     1294 b- defN 23-May-05 08:07 nos/cli/hub.py
 -rw-rw-r--  2.0 unx     7543 b- defN 23-Jun-04 17:53 nos/cli/predict.py
 -rw-rw-r--  2.0 unx     5962 b- defN 23-May-15 21:47 nos/cli/serve_http.py
--rw-rw-r--  2.0 unx     1706 b- defN 23-Jul-15 01:04 nos/cli/system.py
+-rw-rw-r--  2.0 unx     1706 b- defN 23-Jul-13 19:08 nos/cli/system.py
 -rw-rw-r--  2.0 unx      425 b- defN 23-May-09 22:15 nos/cli/utils.py
 -rw-rw-r--  2.0 unx      396 b- defN 23-Jul-05 07:11 nos/client/__init__.py
--rw-rw-r--  2.0 unx      351 b- defN 23-Jul-15 01:04 nos/client/exceptions.py
--rw-rw-r--  2.0 unx    21230 b- defN 23-Jul-20 18:56 nos/client/grpc.py
--rw-rw-r--  2.0 unx     2257 b- defN 23-Jul-20 16:24 nos/common/__init__.py
+-rw-rw-r--  2.0 unx      351 b- defN 23-Jul-13 22:42 nos/client/exceptions.py
+-rw-rw-r--  2.0 unx    13192 b- defN 23-Jul-14 18:16 nos/client/grpc.py
+-rw-rw-r--  2.0 unx     1285 b- defN 23-Jul-13 16:56 nos/common/__init__.py
 -rw-rw-r--  2.0 unx      204 b- defN 23-May-28 04:11 nos/common/cloudpickle.py
--rw-rw-r--  2.0 unx    10364 b- defN 23-Jul-15 01:04 nos/common/profiler.py
--rw-rw-r--  2.0 unx    11782 b- defN 23-Jul-20 16:47 nos/common/shm.py
--rw-rw-r--  2.0 unx     9446 b- defN 23-Jul-19 17:16 nos/common/spec.py
+-rw-rw-r--  2.0 unx    10364 b- defN 23-Jul-14 21:48 nos/common/profiler.py
+-rw-rw-r--  2.0 unx     9446 b- defN 23-Jun-15 22:10 nos/common/spec.py
 -rw-rw-r--  2.0 unx     6076 b- defN 23-Jul-13 19:52 nos/common/system.py
--rw-rw-r--  2.0 unx      569 b- defN 23-Jul-15 01:15 nos/common/tasks.py
+-rw-rw-r--  2.0 unx      593 b- defN 23-Jul-13 16:56 nos/common/tasks.py
 -rw-rw-r--  2.0 unx     5984 b- defN 23-Jun-15 22:10 nos/common/types.py
--rw-rw-r--  2.0 unx     1499 b- defN 23-Jul-20 21:11 nos/common/io/__init__.py
+-rw-rw-r--  2.0 unx     1499 b- defN 23-Jul-14 19:09 nos/common/io/__init__.py
 -rw-rw-r--  2.0 unx     1050 b- defN 23-Jun-15 06:14 nos/common/io/video/base.py
 -rw-rw-r--  2.0 unx     8424 b- defN 23-Jun-15 17:06 nos/common/io/video/opencv.py
 -rw-rw-r--  2.0 unx     5832 b- defN 23-Jun-30 21:21 nos/compilers/__init__.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Jun-28 04:05 nos/compilers/trt/__init__.py
 -rw-rw-r--  2.0 unx     2739 b- defN 23-Jun-28 04:05 nos/compilers/trt/ops/group_norm.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-May-18 17:00 nos/executors/__init__.py
--rw-rw-r--  2.0 unx     7544 b- defN 23-Jul-20 21:11 nos/executors/ray.py
--rw-rw-r--  2.0 unx     3615 b- defN 23-Jul-20 15:53 nos/hub/__init__.py
+-rw-rw-r--  2.0 unx     7544 b- defN 23-Jul-07 20:28 nos/executors/ray.py
+-rw-rw-r--  2.0 unx     3615 b- defN 23-Jul-13 18:49 nos/hub/__init__.py
 -rw-rw-r--  2.0 unx     2195 b- defN 23-Jun-01 19:04 nos/hub/config.py
 -rw-rw-r--  2.0 unx       59 b- defN 23-Jun-15 22:10 nos/managers/__init__.py
--rw-rw-r--  2.0 unx     7987 b- defN 23-Jul-20 15:53 nos/managers/model.py
--rw-rw-r--  2.0 unx      539 b- defN 23-Jul-15 03:56 nos/models/__init__.py
--rw-rw-r--  2.0 unx      922 b- defN 23-Jul-19 20:25 nos/models/_noop.py
+-rw-rw-r--  2.0 unx     7911 b- defN 23-Jul-14 17:38 nos/managers/model.py
+-rw-rw-r--  2.0 unx      339 b- defN 23-Jul-13 22:53 nos/models/__init__.py
+-rw-rw-r--  2.0 unx      879 b- defN 23-Jul-14 19:29 nos/models/_noop.py
 -rw-rw-r--  2.0 unx     9931 b- defN 23-Jul-10 17:19 nos/models/clip.py
--rw-rw-r--  2.0 unx     2834 b- defN 23-Jul-15 01:04 nos/models/faster_rcnn.py
+-rw-rw-r--  2.0 unx     2834 b- defN 23-Jul-14 19:19 nos/models/faster_rcnn.py
 -rw-rw-r--  2.0 unx     1507 b- defN 23-Jul-08 01:45 nos/models/sam.py
 -rw-rw-r--  2.0 unx    16095 b- defN 23-Jul-08 01:45 nos/models/stable_diffusion.py
 -rw-rw-r--  2.0 unx    10128 b- defN 23-Jul-14 20:38 nos/models/yolox.py
 -rw-rw-r--  2.0 unx       63 b- defN 23-Jun-02 17:26 nos/models/openmmlab/__init__.py
 -rw-rw-r--  2.0 unx     3066 b- defN 23-Jun-09 19:19 nos/models/openmmlab/mmdetection/mmdetection.py
 -rw-rw-r--  2.0 unx      370 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/default_runtime.py
 -rw-rw-r--  2.0 unx     3187 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_detection.py
 -rw-rw-r--  2.0 unx     1765 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_instance.py
 -rw-rw-r--  2.0 unx     3828 b- defN 23-May-10 02:43 nos/models/openmmlab/mmdetection/configs/_base_/models/faster-rcnn_r50_fpn.py
 -rw-rw-r--  2.0 unx      304 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/schedules/schedule_1x.py
 -rw-rw-r--  2.0 unx     5340 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/efficientdet/efficientdet_effb3_bifpn_8xb16-crop896-300e_coco.py
 -rw-rw-r--  2.0 unx      177 b- defN 23-May-10 02:43 nos/models/openmmlab/mmdetection/configs/faster-rcnn/faster-rcnn_r50_fpn_1x_coco.py
--rw-rw-r--  2.0 unx     2850 b- defN 23-Jul-18 16:40 nos/proto/nos_service.proto
--rw-rw-r--  2.0 unx    10206 b- defN 23-Jul-19 21:12 nos/server/__init__.py
--rw-rw-r--  2.0 unx     6724 b- defN 23-Jul-17 21:14 nos/server/_docker.py
--rw-rw-r--  2.0 unx     6766 b- defN 23-Jul-20 15:53 nos/server/_runtime.py
--rw-rw-r--  2.0 unx    11883 b- defN 23-Jul-20 15:53 nos/server/_service.py
+-rw-rw-r--  2.0 unx     2437 b- defN 23-Jul-13 16:56 nos/proto/nos_service.proto
+-rw-rw-r--  2.0 unx    10198 b- defN 23-Jul-14 23:41 nos/server/__init__.py
+-rw-rw-r--  2.0 unx     6725 b- defN 23-Jul-13 19:27 nos/server/_docker.py
+-rw-rw-r--  2.0 unx     6482 b- defN 23-Jul-14 21:09 nos/server/_runtime.py
+-rw-rw-r--  2.0 unx     7989 b- defN 23-Jul-14 23:49 nos/server/_service.py
 -rw-rw-r--  2.0 unx      373 b- defN 23-Jul-14 17:54 nos/test/benchmark.py
--rw-rw-r--  2.0 unx     5498 b- defN 23-Jul-17 20:39 nos/test/conftest.py
+-rw-rw-r--  2.0 unx     4237 b- defN 23-Jul-13 21:24 nos/test/conftest.py
 -rw-rw-r--  2.0 unx     2626 b- defN 23-Jul-07 20:28 nos/test/utils.py
--rw-r--r--  2.0 unx     1068 b- defN 23-Jul-20 22:33 autonomi_nos-0.0.7.dist-info/LICENSE
--rw-rw-r--  2.0 unx     6798 b- defN 23-Jul-20 22:33 autonomi_nos-0.0.7.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Jul-20 22:33 autonomi_nos-0.0.7.dist-info/WHEEL
--rw-rw-r--  2.0 unx       87 b- defN 23-Jul-20 22:33 autonomi_nos-0.0.7.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       12 b- defN 23-Jul-20 22:33 autonomi_nos-0.0.7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     5666 b- defN 23-Jul-20 22:33 autonomi_nos-0.0.7.dist-info/RECORD
-67 files, 268124 bytes uncompressed, 82035 bytes compressed:  69.4%
+-rw-r--r--  2.0 unx     1068 b- defN 23-Jul-14 23:58 autonomi_nos-0.0.7a2.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     6800 b- defN 23-Jul-14 23:58 autonomi_nos-0.0.7a2.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jul-14 23:58 autonomi_nos-0.0.7a2.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       87 b- defN 23-Jul-14 23:58 autonomi_nos-0.0.7a2.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       12 b- defN 23-Jul-14 23:58 autonomi_nos-0.0.7a2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     5602 b- defN 23-Jul-14 23:58 autonomi_nos-0.0.7a2.dist-info/RECORD
+66 files, 240997 bytes uncompressed, 75220 bytes compressed:  68.8%
```

## zipnote {}

```diff
@@ -54,17 +54,14 @@
 
 Filename: nos/common/cloudpickle.py
 Comment: 
 
 Filename: nos/common/profiler.py
 Comment: 
 
-Filename: nos/common/shm.py
-Comment: 
-
 Filename: nos/common/spec.py
 Comment: 
 
 Filename: nos/common/system.py
 Comment: 
 
 Filename: nos/common/tasks.py
@@ -177,26 +174,26 @@
 
 Filename: nos/test/conftest.py
 Comment: 
 
 Filename: nos/test/utils.py
 Comment: 
 
-Filename: autonomi_nos-0.0.7.dist-info/LICENSE
+Filename: autonomi_nos-0.0.7a2.dist-info/LICENSE
 Comment: 
 
-Filename: autonomi_nos-0.0.7.dist-info/METADATA
+Filename: autonomi_nos-0.0.7a2.dist-info/METADATA
 Comment: 
 
-Filename: autonomi_nos-0.0.7.dist-info/WHEEL
+Filename: autonomi_nos-0.0.7a2.dist-info/WHEEL
 Comment: 
 
-Filename: autonomi_nos-0.0.7.dist-info/entry_points.txt
+Filename: autonomi_nos-0.0.7a2.dist-info/entry_points.txt
 Comment: 
 
-Filename: autonomi_nos-0.0.7.dist-info/top_level.txt
+Filename: autonomi_nos-0.0.7a2.dist-info/top_level.txt
 Comment: 
 
-Filename: autonomi_nos-0.0.7.dist-info/RECORD
+Filename: autonomi_nos-0.0.7a2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## nos/constants.py

```diff
@@ -14,8 +14,8 @@
 NOS_MODELS_DIR.mkdir(parents=True, exist_ok=True)
 NOS_LOG_DIR.mkdir(parents=True, exist_ok=True)
 NOS_TMP_DIR.mkdir(parents=True, exist_ok=True)
 
 DEFAULT_GRPC_PORT = 50051
 DEFAULT_HTTP_PORT = 8000
 
-NOS_PROFILING_ENABLED = bool(int(os.getenv("NOS_PROFILING_ENABLED", "0")))
+NOS_PROFILING_ENABLED = bool(int(os.getenv("NOS_PROFILING_ENABLED", 0)))
```

## nos/protoc.py

```diff
@@ -25,55 +25,54 @@
     def __init__(self) -> None:
         self.cache_dir.mkdir(parents=True, exist_ok=True)
 
         # Add cache dir to sys.path
         sys.path.append(str(self.cache_dir))
 
         # Compile all proto files from all paths
-        logger.debug(f"Compiling protos [dirs={PROTO_PATHS}]")
+        logger.debug(f"Compiling protos from: {PROTO_PATHS}")
         for path in itertools.chain.from_iterable(Path(path).glob("*.proto") for path in PROTO_PATHS):
-            logger.debug(f"Compiling ... [filename={path}]")
+            logger.debug(f"Compiling {path}")
             self.compile(str(path))
-        logger.debug(f"Compiled modules [modules={self.list_modules()}]")
+        logger.debug(f"Compiled modules: {self.list_modules()}")
 
     @classmethod
     def get(cls: "DynamicProtobufCompiler") -> "DynamicProtobufCompiler":
         """Get DynamicProtobufCompiler."""
         if cls._instance is None:
             cls._instance = cls()
         return cls._instance
 
     def compile(self, proto_filename: str):
         """Compile the proto file to generate the Python modules"""
-        logger.debug(f"Compiling proto [proto={proto_filename}]")
         cmd = [
             "",
             "-I" + str(Path(protoc.__file__).parent / "_proto/"),
             f"--python_out={self.cache_dir}",
             f"--grpc_python_out={self.cache_dir}",
             f"--proto_path={Path(proto_filename).parent}",
             f"{Path(proto_filename).name}",
         ]
-        logger.debug(f"Compiling proto [cmd=protoc {' '.join(cmd)}]")
+        logger.debug(f"Compiling protos: {' '.join(cmd)}")
 
         st = time.time()
         protoc.main(cmd)
-        logger.debug(f"Compilation done [elapsed={(time.time() - st)*1e3:.1f}ms]")
+        logger.debug(f"Compilation took: {time.time() - st:.2f} seconds")
 
     def list_modules(self) -> List[str]:
         """Return a list of compiled modules."""
         return [Path(path).stem for path in self.cache_dir.glob("*_pb2*.py")]
 
     def import_module(self, module_name: str):
         """Import the specified module and return the imported module object."""
         import importlib.util
 
         # Load the module
         module_path = f"{Path(self.cache_dir) / module_name}.py"
-        logger.debug(f"Loading module [module={module_path}]")
+        logger.debug(f"Loading module: {module_path}")
         spec = importlib.util.spec_from_file_location(module_name, module_path)
 
         module = importlib.util.module_from_spec(spec)
         spec.loader.exec_module(module)
         return module
```

## nos/version.py

```diff
@@ -1 +1 @@
-__version__ = "0.0.7"
+__version__ = "0.0.7a2"
```

## nos/client/grpc.py

```diff
@@ -1,22 +1,19 @@
 """gRPC client for NOS service."""
-import secrets
 import time
+import traceback
 from dataclasses import dataclass, field
-from functools import cached_property, lru_cache
+from functools import lru_cache
 from typing import Any, Callable, Dict, List
 
 import grpc
-import numpy as np
 from google.protobuf import empty_pb2
-from PIL import Image
 
 from nos.client.exceptions import NosClientException
-from nos.common import FunctionSignature, ModelSpec, TaskType, TensorSpec, dumps, loads
-from nos.common.shm import NOS_SHM_ENABLED, SharedMemoryTransportManager
+from nos.common import ModelSpec, TaskType, loads
 from nos.constants import DEFAULT_GRPC_PORT, NOS_PROFILING_ENABLED
 from nos.logging import logger
 from nos.protoc import import_module
 from nos.version import __version__
 
 
 nos_service_pb2 = import_module("nos_service_pb2")
@@ -63,15 +60,14 @@
 
         Args:
             address (str): Address for the gRPC server. Defaults to f"[::]:{DEFAULT_GRPC_PORT}".
         """
         self.address: str = address
         self._channel: grpc.Channel = None
         self._stub: nos_service_pb2_grpc.InferenceServiceStub = None
-        self._uuid: str = secrets.token_hex(4)
 
     def __getstate__(self) -> InferenceClientState:
         """Returns the state of the client for serialization purposes.
 
         Returns:
             InferenceClientState: State of the client.
         """
@@ -287,190 +283,27 @@
     """
     model_name: str
     """Model identifier (e.g. openai/clip-vit-base-patch32)."""
     _client: InferenceClient
     """gRPC client."""
     _spec: ModelSpec = field(init=False)
     """Model specification for this module."""
-    _shm_objects: Dict[str, Any] = field(init=False, default_factory=dict)
-    """Shared memory data."""
 
     def __post_init__(self):
         """Initialize the spec."""
         self._spec = self._client.GetModelInfo(ModelSpec(name=self.model_name, task=self.task))
-        if not NOS_SHM_ENABLED:
-            self._shm_objects = None  # disables shm, and avoids registering/unregistering
 
     @property
     def stub(self):
         return self._client.stub
 
-    @property
-    def client_id(self) -> str:
-        """Correlation ID for this module."""
-        return self._client._uuid
-
-    @cached_property
-    def object_id(self) -> str:
-        """Unique object ID for this module."""
-        return f"{self._spec.id}_{secrets.token_hex(4)}"
-
-    @cached_property
-    def namespace(self) -> str:
-        """Unique namespace for this module."""
-        return f"{self.client_id}/{self.object_id}"
-
-    def _encode(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        """Encode the inputs dictionary for transmission.
-        TODO (spillai)
-            - Support middlewares for encoding/decoding.
-            - Validate inputs/outputs with spec signature.
-            - Support shared memory transport.
-            - SerDe before/after transmission.
-        Args:
-            inputs (Dict[str, Any]): Inputs to the model ("images", "texts", "prompts" etc) as
-                defined in the ModelSpec.signature.inputs.
-        Returns:
-            Dict[str, Any]: Encoded inputs.
-        """
-        # Validate data with spec signature
-        inputs = FunctionSignature.validate(inputs, self._spec.signature.inputs)
-
-        # Encode List[np.ndarray] as stacked np.ndarray (B, H, W, C)
-        for k, v in inputs.items():
-            if isinstance(v, Image.Image):
-                inputs[k] = np.asarray(v)
-            elif isinstance(v, list) and isinstance(v[0], Image.Image):
-                inputs[k] = np.stack([np.asarray(_v) for _v in v], axis=0)
-            elif isinstance(v, list) and isinstance(v[0], np.ndarray):
-                inputs[k] = np.stack(v, axis=0)
-
-        # Optionally, create/register shm and copy over numpy arrays to shm
-        if self._shm_objects is not None:
-            # If inputs are already registered, check if they've changed
-            # If they've changed, unregister and re-register.
-            # Checks: 1) keys match, 2) inputs are np.ndarray, 3) shapes match
-            if len(self._shm_objects):
-                valid = inputs.keys() == self._shm_objects.keys()
-                for k, v in inputs.items():
-                    try:
-                        valid &= isinstance(v, np.ndarray)
-                        if valid and isinstance(v, np.ndarray):
-                            valid &= v.shape == self._shm_objects[k].shape
-                    except Exception:
-                        valid = False
-                if not valid:
-                    logger.debug(
-                        """Inputs are inconsistent with previously registered shared memory objects, unregistering ..."""
-                    )
-                    registered_str = [(k, type(v), v.shape) for k, v in self._shm_objects.items()]
-                    inputs_str = [
-                        (k, type(v), v.shape if isinstance(v, np.ndarray) else None) for k, v in inputs.items()
-                    ]
-                    logger.debug(
-                        f"""Unregistering due to inconsistent shapes ... [registered={registered_str}, """
-                        f"""inputs={inputs_str}]"""
-                    )
-                    self.UnregisterSystemSharedMemory()
-
-            # Register system shared memory for inputs, if not already registered
-            if not len(self._shm_objects):
-                self.RegisterSystemSharedMemory(inputs)
-
-        # Copy data from numpy array to shared memory
-        if self._shm_objects is not None and len(self._shm_objects):
-            inputs = SharedMemoryTransportManager.copy(self._shm_objects, inputs)
-
-        # Pickle the data for transmission
-        return {k: dumps(v) for k, v in inputs.items()}
-
-    def _decode(self, response_bytes: bytes) -> Any:
-        """Decode the response bytes."""
-        return loads(response_bytes)
-
-    def __del__(self):
-        """Delete the shared memory."""
-        self.UnregisterSystemSharedMemory()
-
     def GetModelInfo(self) -> ModelSpec:
         """Get the relevant model information from the model name."""
         return self._spec
 
-    def RegisterSystemSharedMemory(self, inputs: Dict[str, Any]) -> None:
-        """Register system shared memory for inputs.
-
-        Args:
-            inputs (Dict[str, Any]): Inputs to the model ("images", "texts", "prompts" etc) as
-                defined in the ModelSpec.signature.inputs. For example, {"images": np.ndarray}.
-        """
-
-        # Create shared memory request
-        # We convert the numpy arrays to TensorSpec(s) to let the
-        # server know the shape and dtype of the underlying shm data.
-        if not NOS_SHM_ENABLED:
-            logger.warning("Shared memory is not enabled, skipping.")
-            return
-
-        shm_request = {}
-        for k, v in inputs.items():
-            if isinstance(v, np.ndarray):
-                shm_request[k] = TensorSpec(v.shape, dtype=str(v.dtype))
-        if not len(shm_request):
-            logger.debug(f"Skipping shm registration, no numpy arrays found in inputs [inputs={inputs}]")
-            return
-        logger.debug(f"Registering shm [request={shm_request}]")
-
-        # Request shared memory, fail gracefully if not supported
-        try:
-            # Clear the cached object_id and namespace so that they are re-initialized
-            if "object_id" in self.__dict__:  # noqa: WPS421
-                del self.object_id
-                del self.namespace
-            response = self.stub.RegisterSystemSharedMemory(
-                nos_service_pb2.GenericRequest(request_bytes=dumps(shm_request)),
-                metadata=[("client_id", self.client_id), ("object_id", self.object_id)],
-            )
-
-            # Register the shared memory objects by name on the client
-            # Note (spillai): This calls __setstate__ on the SharedMemoryNumpyObject
-            self._shm_objects = loads(response.response_bytes)
-            logger.debug(f"Registered shm [namespace={self.namespace}, objects={self._shm_objects}]")
-        except grpc.RpcError as e:
-            logger.error(f"Failed to register shm [request={shm_request}], error: {e.details()}")
-            raise NosClientException(f"Failed to register shm [request={shm_request}, e={e.details()}]", e)
-
-    def UnregisterSystemSharedMemory(self) -> None:
-        """Unregister system shared memory."""
-        if not NOS_SHM_ENABLED:
-            logger.warning("Shared memory is not enabled, skipping.")
-            return
-
-        if self._shm_objects is not None and len(self._shm_objects):
-            logger.debug(
-                f"Unregistering shm [namespace={self.namespace}, objects={[(k, v) for k, v in self._shm_objects.items()]}"
-            )
-
-            # Close the shared memory objects
-            shm_objects_name_map = {k: v.name for k, v in self._shm_objects.items()}
-            for _k, v in self._shm_objects.items():
-                v.close()
-
-            # Unregister the shared memory objects on the server
-            try:
-                self.stub.UnregisterSystemSharedMemory(
-                    nos_service_pb2.GenericRequest(request_bytes=dumps(shm_objects_name_map)),
-                    metadata=[("client_id", self.client_id), ("object_id", self.object_id)],
-                )
-                # Delete the shared memory objects after safely closing (client-side) and unregistering them (server-side).
-                self._shm_objects = {}
-                logger.debug(f"Unregistered shm [{self._shm_objects}]")
-            except grpc.RpcError as e:
-                logger.error(f"Failed to unregister shm [{self._shm_objects}], error: {e.details()}")
-                raise NosClientException(f"Failed to unregister shm [{self._shm_objects}]", e)
-
     def __call__(self, **inputs: Dict[str, Any]) -> Dict[str, Any]:
         """Call the instantiated module/model.
 
         Args:
             **inputs (Dict[str, Any]): Inputs to the model ("images", "texts", "prompts" etc) as
                 defined in the ModelSpec.signature.inputs.
         Returns:
@@ -478,37 +311,38 @@
         Raises:
             NosClientException: If the server fails to respond to the request.
         """
         # Check if the input dictionary is consistent
         # with inputs/outputs defined in `spec.signature`
         # and then encode it.
         st = time.perf_counter()
-        inputs = self._encode(inputs)
+        inputs = self._spec.signature._encode_inputs(inputs)
         if NOS_PROFILING_ENABLED:
-            logger.debug(f"Encoded inputs [model={self._spec.name}, elapsed={(time.perf_counter() - st) * 1e3:.1f}ms]")
+            logger.debug(f"Encoded inputs, elapsed={(time.perf_counter() - st) * 1e3:.1f}ms")
         request = nos_service_pb2.InferenceRequest(
             model=nos_service_pb2.ModelInfo(
                 task=self.task.value,
                 name=self.model_name,
             ),
             inputs=inputs,
         )
         try:
-            st = time.perf_counter()
-            logger.debug(f"Executing request [model={self._spec.name}]]")
+            mid = time.perf_counter()
             response = self.stub.Run(request)
             if NOS_PROFILING_ENABLED:
-                logger.debug(
-                    f"Executed request [model={self._spec.name}, elapsed={(time.perf_counter() - st) * 1e3:.1f}ms]"
-                )
+                logger.debug(f"Executed request, elapsed={(time.perf_counter() - mid) * 1e3:.1f}ms")
 
-            st = time.perf_counter()
-            response = self._decode(response.response_bytes)
-            response = {k: loads(v) for k, v in response.items()}
+            mid = time.perf_counter()
+            response = loads(response.response_bytes)
             if NOS_PROFILING_ENABLED:
-                logger.debug(
-                    f"Decoded response [model={self._spec.name}, elapsed={(time.perf_counter() - st) * 1e3:.1f}ms]"
-                )
+                logger.debug(f"Decoded response, elapsed={(time.perf_counter() - mid) * 1e3:.1f}ms")
             return response
         except grpc.RpcError as e:
-            logger.error(f"Run() failed [details={e.details()}, request={request}, inputs={inputs.keys()}]")
-            raise NosClientException(f"Run() failed [model={self.model_name}, details={e.details()}]", e)
+            logger.error(
+                f"""Run() failed"""
+                f"""\nrequest={request}"""
+                f"""\ninputs={inputs}"""
+                f"""\nerror: {e.details()}"""
+                f"""\n\nTraceback"""
+                f"""\n{traceback.format_exc()}"""
+            )
+            raise NosClientException(f"Failed to run model {self.model_name} (details={e.details()})", e)
```

## nos/common/__init__.py

```diff
@@ -1,15 +1,13 @@
-import contextlib
 import time
 from typing import Any
 
 from tqdm import tqdm as _tqdm
 
 from .cloudpickle import dumps, loads
-from .shm import SharedMemoryDataDict, SharedMemoryNumpyObject, SharedMemoryTransportManager  # noqa: F401
 from .spec import FunctionSignature, ModelSpec, ObjectTypeInfo
 from .tasks import TaskType
 from .types import Batch, EmbeddingSpec, ImageSpec, ImageT, TensorSpec, TensorT
 
 
 def tqdm(iterable: Any = None, *args, **kwargs) -> Any:
     """Wrapper around tqdm that allows for a duration to be
@@ -27,47 +25,19 @@
     try:
         duration_s = kwargs.pop("duration")
         duration_ms = duration_s * 1_000
     except KeyError:
         raise KeyError("`duration` must be specified when no iterable is provided")
 
     # Yield progress bar for the specified duration
-    def _iterable():
+    def iterable():
         idx = 0
         st_ms = time.perf_counter() * 1_000
         while True:
             now_ms = time.perf_counter() * 1_000
             elapsed_ms = now_ms - st_ms
             if elapsed_ms >= duration_ms:
                 return
             yield idx
             idx += 1
 
-    return _tqdm(_iterable(), *args, **kwargs)
-
-
-class TimingInfo:
-    """Timing information for a context manager"""
-
-    def __init__(self, desc: str, elapsed: float = 0.0, **kwargs):
-        self.desc = desc
-        self.elapsed = elapsed
-        self.kwargs = kwargs
-
-    def __repr__(self):
-        repr_str = f"{self.__class__.__name__}(desc={self.desc}"
-        if len(self.kwargs):
-            repr_str += ", " + ", ".join([f"{k}={v}" for k, v in self.kwargs.items()])
-        repr_str += f", elapsed={self.elapsed:.2f}s)"
-        return repr_str
-
-    def to_dict(self):
-        return {**self.kwargs, "desc": self.desc, "elapsed": self.elapsed}
-
-
-@contextlib.contextmanager
-def timer(desc: str = "", **kwargs):
-    """Simple context manager for timing code blocks"""
-    info = TimingInfo(desc, **kwargs)
-    start = time.time()
-    yield info
-    info.elapsed = time.time() - start
+    return _tqdm(iterable(), *args, **kwargs)
```

## nos/common/tasks.py

```diff
@@ -16,8 +16,8 @@
 
     IMAGE_EMBEDDING = "image_embedding"
     """Image embedding."""
     TEXT_EMBEDDING = "text_embedding"
     """Text embedding."""
 
     CUSTOM = "custom"
-    """Custom task type."""
+    """Noop GPRC call for benchrmarking purposes"""
```

## nos/managers/model.py

```diff
@@ -173,42 +173,42 @@
             ValueError: If the model already exists.
         Returns:
             ModelHandle: Model handle.
         """
         # If the model already exists, raise an error
         model_id = spec.id
         if model_id in self.handlers:
-            raise ValueError(f"Model already exists [model_id={model_id}]")
+            raise ValueError(f"Model already exists: {model_id}")
 
         # If the model handle is full, pop the oldest model
         if len(self.handlers) >= self.max_concurrent_models:
             _handle: ModelHandle = self.evict()
-            logger.debug(f"Deleting oldest model [model={_handle.spec.name}]")
+            logger.debug(f"Deleting oldest model: {_handle.spec.name}")
 
         # Create the serve deployment from the model handle
-        logger.debug(f"Initializing model with spec [model={spec.name}]")
+        logger.debug(f"Initializing model with spec: {spec.name}")
 
         # Note: Currently one model per (model-name, task) is supported.
         self.handlers[model_id] = ModelHandle(spec)
-        logger.debug(f"Created actor [handle={self.handlers[model_id]}, type={type(self.handlers[model_id])}]")
-        logger.debug(f"Active models ({len(self.handlers)}): {list(self.handlers.keys())})")
+        logger.debug(f"Created actor: {self.handlers[model_id]}, type={type(self.handlers[model_id])}")
+        logger.debug(f"Models ({len(self.handlers)}): {self.handlers.keys()}")
 
         return self.handlers[model_id]
 
     def evict(self) -> ModelHandle:
         """Evict a model from the manager (FIFO, LRU etc).
 
         Returns:
             ModelHandle: Model handle.
         """
         # Pop the oldest model
         # TODO (spillai): Implement LRU policy
         assert len(self.handlers) > 0, "No models to evict."
         _, handle = self.handlers.popitem(last=False)
         model_id = handle.spec.id
-        logger.debug(f"Deleting model [model_id={model_id}]")
+        logger.debug(f"Deleting model: {model_id}")
 
         # Explicitly kill the model handle (including all actors)
         handle.kill()
-        logger.debug(f"Deleted model [model_id={model_id}]")
-        assert model_id not in self.handlers, f"Model should have been evicted [model_id={model_id}]"
+        logger.debug(f"Deleted model: {model_id}")
+        assert model_id not in self.handlers, f"Model should have been evicted: {model_id}"
         return handle
```

## nos/models/__init__.py

```diff
@@ -1,16 +1,8 @@
-from dataclasses import dataclass
-from typing import Dict, List, Union
-
-import numpy as np
-from PIL import Image
-
 from nos import hub
-from nos.common import ImageSpec, TaskType
-from nos.common.types import Batch, ImageT
 
 from ._noop import NoOp  # noqa: F401
 from .clip import CLIP  # noqa: F401
 from .faster_rcnn import FasterRCNN  # noqa: F401
 from .openmmlab.mmdetection.mmdetection import MMDetection  # noqa: F401
 from .sam import SAM
 from .stable_diffusion import StableDiffusion  # noqa: F401
```

## nos/models/_noop.py

```diff
@@ -10,15 +10,15 @@
 
 class NoOp:
     """No-op model."""
 
     def process_images(
         self, images: Union[Image.Image, np.ndarray, List[Image.Image], List[np.ndarray]]
     ) -> Dict[str, np.ndarray]:
-        if (isinstance(images, np.ndarray) and images.ndim == 3) or isinstance(images, Image.Image):
+        if isinstance(images, (Image.Image, np.ndarray)):
             images = [images]
         return list(range(len(images)))
 
 
 hub.register(
     "noop/process-images",
     TaskType.CUSTOM,
```

## nos/proto/nos_service.proto

```diff
@@ -63,24 +63,14 @@
 }
 
 // Service information repsonse
 message ServiceInfoResponse {
     string version = 1;  // (e.g. "0.1.0")
 }
 
-// Register system shared memory request
-message GenericRequest {
-  bytes request_bytes = 1;
-}
-
-// Register system shared memory response
-message GenericResponse {
-  bytes response_bytes = 1;
-}
-
 // Service definition
 service InferenceService {
   // Check health status of the inference server.
   rpc Ping(google.protobuf.Empty) returns (PingResponse) {}
 
   // Get service information (version, release date etc.)
   rpc GetServiceInfo(google.protobuf.Empty) returns (ServiceInfoResponse) {}
@@ -90,20 +80,14 @@
 
   // Get model information from the deployment
   rpc GetModelInfo(ModelInfoRequest) returns (ModelInfoResponse) {};
 
   // Run the inference request
   rpc Run(InferenceRequest) returns (InferenceResponse) {}
 
-  // Register shared memory
-  rpc RegisterSystemSharedMemory(GenericRequest) returns (GenericResponse) {}
-
-  // Unregister shared memory
-  rpc UnregisterSystemSharedMemory(GenericRequest) returns (GenericResponse) {}
-
   // Load model from Hugging Face Hub
   // TODO (spillai): To be implemented later (for power-users)
   // rpc InitModel(InitModelRequest) returns (InitModelResponse) {}
 
   // Delete model from deployment
   // TODO (spillai): To be implemented later (for power-users)
   // rpc DeleteModel(DeleteModelRequest) returns (DeleteModelResponse) {}
```

## nos/server/__init__.py

```diff
@@ -6,17 +6,17 @@
 
 import psutil
 import rich.status
 
 import docker
 import docker.errors
 import docker.models.containers
+from nos import __version__
 from nos.constants import DEFAULT_GRPC_PORT
 from nos.logging import logger
-from nos.version import __version__
 
 from ._docker import DockerRuntime
 from ._runtime import InferenceServiceRuntime
 
 
 __all__ = ["init", "shutdown"]
```

## nos/server/_docker.py

```diff
@@ -1,10 +1,11 @@
 """Docker utilities to run containerized inference workloads
 (compile/infer) in detached mode.
 """
+
 from dataclasses import dataclass
 from typing import Any, Iterable, List, Optional, Union
 
 import docker
 import docker.errors
 import docker.models.containers
 import docker.models.images
```

## nos/server/_runtime.py

```diff
@@ -1,15 +1,14 @@
 """gRPC server runtime using docker executor."""
 import copy
 from dataclasses import dataclass, field
 from pathlib import Path
 from typing import Any, Dict, Iterable, List, Optional, Union
 
 import docker
-from nos.common.shm import NOS_SHM_ENABLED
 from nos.constants import DEFAULT_GRPC_PORT, NOS_PROFILING_ENABLED  # noqa F401
 from nos.logging import LOGGING_LEVEL, logger
 from nos.protoc import import_module
 from nos.version import __version__
 
 from ._docker import DockerRuntime
 
@@ -42,33 +41,28 @@
     ports: Dict[int, int] = field(default_factory=lambda: {DEFAULT_GRPC_PORT: DEFAULT_GRPC_PORT})
     """Ports to expose."""
 
     environment: Dict[str, str] = field(
         default_factory=lambda: {
             "NOS_LOGGING_LEVEL": LOGGING_LEVEL,
             "NOS_PROFILING_ENABLED": int(NOS_PROFILING_ENABLED),
-            "NOS_SHM_ENABLED": int(NOS_SHM_ENABLED),
         }
     )
     """Environment variables."""
 
     volumes: Dict[str, Dict[str, str]] = field(
         default_factory=lambda: {
-            str(Path.home() / ".nosd"): {"bind": "/app/.nos", "mode": "rw"},  # nos cache
-            "/dev/shm": {"bind": "/dev/shm", "mode": "rw"},  # shared-memory transport
+            str(Path.home() / ".nosd"): {"bind": "/app/.nos", "mode": "rw"},
         }
     )
     """Volumes to mount."""
 
     shm_size: str = "4g"
     """Size of /dev/shm."""
 
-    ipc_mode: str = "host"
-    """IPC mode."""
-
     detach: bool = True
     """Whether to run the container in detached mode."""
 
     gpu: bool = False
     """Whether to start the container with GPU support."""
 
     kwargs: Dict[str, Any] = field(
@@ -172,15 +166,14 @@
             name=self.cfg.name,
             command=self.cfg.command,
             ports=self.cfg.ports,
             environment=self.cfg.environment,
             volumes=self.cfg.volumes,
             detach=self.cfg.detach,
             gpu=self.cfg.gpu,
-            ipc_mode=self.cfg.ipc_mode,
             **self.cfg.kwargs,
         )
         logger.debug(f"Started inference runtime: {self}")
         return container
 
     def stop(self, timeout: int = 30) -> docker.models.containers.Container:
         return self._runtime.stop(self.cfg.name, timeout=timeout)
```

## nos/server/_service.py

```diff
@@ -5,20 +5,16 @@
 
 import grpc
 import rich.console
 import rich.status
 from google.protobuf import empty_pb2
 
 from nos import hub
-from nos.common import FunctionSignature, ModelSpec, TaskType, dumps, loads
-from nos.common.shm import NOS_SHM_ENABLED, SharedMemoryDataDict, SharedMemoryTransportManager
-from nos.constants import (  # noqa F401
-    DEFAULT_GRPC_PORT,  # noqa F401
-    NOS_PROFILING_ENABLED,
-)
+from nos.common import ModelSpec, TaskType, dumps
+from nos.constants import DEFAULT_GRPC_PORT, NOS_PROFILING_ENABLED  # noqa F401
 from nos.exceptions import ModelNotFoundError
 from nos.executors.ray import RayExecutor
 from nos.logging import logger
 from nos.managers import ModelHandle, ModelManager
 from nos.protoc import import_module
 from nos.version import __version__
 
@@ -27,44 +23,36 @@
 nos_service_pb2_grpc = import_module("nos_service_pb2_grpc")
 
 
 @lru_cache(maxsize=32)
 def load_spec(model_name: str, task: TaskType) -> ModelSpec:
     """Get the model spec cache."""
     model_spec: ModelSpec = hub.load_spec(model_name, task=task)
-    logger.info(f"Loaded model spec [task={model_spec.task.value}, name={model_spec.name}]")
+    logger.info(f"Loaded model spec: {model_spec}")
     return model_spec
 
 
 class InferenceService:
     """Ray-executor based inference service.
 
     Parameters:
         model_manager (ModelManager): Model manager.
         executor (RayExecutor): Ray executor.
-        shm_manager (SharedMemoryTransportManager): Shared memory transport manager.
-            Used to create shared memory buffers for inputs/outputs,
-            and to copy data to/from shared memory.
 
     Note: To be used with the `InferenceServiceImpl` gRPC service.
     """
 
     def __init__(self):
         self.model_manager = ModelManager()
         self.executor = RayExecutor.get()
         try:
             self.executor.init()
         except Exception as e:
-            err_msg = f"Failed to initialize executor [e={e}]"
-            logger.info(err_msg)
-            raise RuntimeError(err_msg)
-        if NOS_SHM_ENABLED:
-            self.shm_manager = SharedMemoryTransportManager()
-        else:
-            self.shm_manager = None
+            logger.info(f"Failed to initialize executor: {e}")
+            raise RuntimeError(f"Failed to initialize executor: {e}")
 
     def execute(self, model_name: str, task: TaskType = None, inputs: Dict[str, Any] = None) -> Dict[str, Any]:
         """Execute the model.
 
         Args:
             model_name (str): Model identifier (e.g. `openai/clip-vit-base-patch32`).
             task (TaskType): Task type (e.g. `TaskType.OBJECT_DETECTION_2D`).
@@ -72,50 +60,41 @@
         Returns:
             Dict[str, Any]: Model outputs.
         """
         # Load the model spec
         try:
             model_spec: ModelSpec = load_spec(model_name, task=task)
         except Exception as e:
-            raise ModelNotFoundError(f"Failed to load model spec [model_name={model_name}, e={e}]")
+            raise ModelNotFoundError(f"Failed to load model spec: {model_name}, {e}")
 
         # TODO (spillai): Validate/Decode the inputs
-        st = time.perf_counter()
-        model_inputs = FunctionSignature.validate(inputs, model_spec.signature.inputs)
-        model_inputs = SharedMemoryDataDict.decode(model_inputs)
-        if NOS_PROFILING_ENABLED:
-            model_inputs_types = [
-                f"{k}: List[type={type(v[0])}, len={len(v)}]" if isinstance(v, list) else str(type(v))
-                for k, v in model_inputs.items()
-            ]
-            logger.debug(
-                f"Decoded inputs [inputs=({', '.join(model_inputs_types)}), elapsed={(time.perf_counter() - st) * 1e3:.1f}ms]"
-            )
+        mid = time.perf_counter()
+        model_inputs = model_spec.signature._decode_inputs(inputs)
+        model_inputs_types = [
+            f"{k}: List[type={type(v[0])}, len={len(v)}]" if isinstance(v, list) else str(type(v))
+            for k, v in model_inputs.items()
+        ]
+        logger.debug(
+            f"Decoded inputs [inputs=({', '.join(model_inputs_types)}), elapsed={(time.perf_counter() - mid) * 1e3:.1f}ms]"
+        )
 
         # Initialize the model (if not already initialized)
         # This call should also evict models and garbage collect if
         # too many models are loaded are loaded simultaneously.
         model_handle: ModelHandle = self.model_manager.get(model_spec)
 
         # Get the model handle and call it remotely (with model spec, actor handle)
-        st = time.perf_counter()
+        mid = time.perf_counter()
         response: Dict[str, Any] = model_handle.remote(**model_inputs)
-        if NOS_PROFILING_ENABLED:
-            logger.debug(f"Executed model [name={model_spec.name}, elapsed={(time.perf_counter() - st) * 1e3:.1f}ms]")
+        logger.debug(f"Executed model [name={model_spec.name}, elapsed={(time.perf_counter() - mid) * 1e3:.1f}ms]")
 
         # If the response is a single value, wrap it in a dict with the appropriate key
         if len(model_spec.signature.outputs) == 1:
             response = {k: response for k in model_spec.signature.outputs}
 
-        # Encode the response
-        st = time.perf_counter()
-        response = SharedMemoryDataDict.encode(response)
-        if NOS_PROFILING_ENABLED:
-            logger.debug(f"Encoded response [elapsed={(time.perf_counter() - st) * 1e3:.1f}ms]")
-
         return response
 
 
 class InferenceServiceImpl(nos_service_pb2_grpc.InferenceServiceServicer, InferenceService):
     """
     Experimental gRPC-based inference service.
 
@@ -148,95 +127,46 @@
     def GetModelInfo(
         self, request: nos_service_pb2.ModelInfoRequest, context: grpc.ServicerContext
     ) -> nos_service_pb2.ModelInfoResponse:
         """Get model information."""
         try:
             model_info = request.request
             spec: ModelSpec = hub.load_spec(model_info.name, task=TaskType(model_info.task))
-            logger.debug(f"GetModelInfo() [spec={spec}]")
+            logger.debug(f"GetModelInfo(): {spec}")
         except KeyError as e:
-            logger.error(f"Failed to load spec [request={request.request}, e={e}]")
+            logger.error(f"Failed to load spec: [request={request.request}, e={e}]")
             context.abort(grpc.StatusCode.NOT_FOUND, str(e))
         return spec._to_proto(public=True)
 
-    def RegisterSystemSharedMemory(
-        self, request: nos_service_pb2.GenericRequest, context: grpc.ServicerContext
-    ) -> nos_service_pb2.GenericResponse:
-        """Register system shared memory under a specific namespace `<client_id>/<object_id>`."""
-        if not NOS_SHM_ENABLED:
-            context.abort(grpc.StatusCode.UNIMPLEMENTED, "Shared memory not enabled.")
-
-        metadata = dict(context.invocation_metadata())
-        client_id = metadata.get("client_id", None)
-        object_id = metadata.get("object_id", None)
-        namespace = f"{client_id}/{object_id}"
-        logger.debug(f"Registering shm [client_id={client_id}, object_id={object_id}]")
-        try:
-            # Create a shared memory segment for the inputs
-            # Note: The returned keys for shared memory segments are identical to the
-            # keys in the input dictionary (i.e. <key>), and are not prefixed with the
-            # namespace `<client_id>/<object_id>`.
-            shm_map = self.shm_manager.create(loads(request.request_bytes), namespace=namespace)
-            # Here, dumps() is used to serialize the shared memory numy objects via __getstate__().
-            # The serialized data is then sent back to the client, which can then deserialized
-            # and set via __setstate__() on the client-side, so that the client can access the shared
-            # memory segments.
-            logger.debug(f"Registered shm [client_id={client_id}, object_id={object_id}, shm_map={shm_map}]")
-            return nos_service_pb2.GenericResponse(response_bytes=dumps(shm_map))
-        except Exception as e:
-            logger.error(f"Failed to register system shared memory: {e}")
-            context.abort(grpc.StatusCode.INTERNAL, str(e))
-
-    def UnregisterSystemSharedMemory(
-        self, request: nos_service_pb2.GenericRequest, context: grpc.ServicerContext
-    ) -> nos_service_pb2.GenericResponse:
-        """Unregister system shared memory for specific namespace `<client_id>/<object_id>`."""
-        if not NOS_SHM_ENABLED:
-            context.abort(context, grpc.StatusCode.UNIMPLEMENTED, "Shared memory not enabled.")
-
-        metadata = dict(context.invocation_metadata())
-        client_id = metadata.get("client_id", None)
-        object_id = metadata.get("object_id", None)
-        namespace = f"{client_id}/{object_id}"
-        # TODO (spillai): Currently, we can ignore the `request` provided
-        # by the client, since all the shared memory segments under the namespace are deleted.
-        logger.debug(f"Unregistering shm [client_id={client_id}, object_id={object_id}]")
-        try:
-            self.shm_manager.cleanup(namespace=namespace)
-        except Exception as e:
-            logger.error(f"Failed to unregister shm [e{e}]")
-            context.abort(grpc.StatusCode.INTERNAL, str(e))
-        return nos_service_pb2.GenericResponse()
-
     def Run(
         self, request: nos_service_pb2.InferenceRequest, context: grpc.ServicerContext
     ) -> nos_service_pb2.InferenceResponse:
         """Main model prediction interface."""
         model_request = request.model
-        logger.debug(f"=> Received request [task={model_request.task}, model={model_request.name}]")
+        logger.debug(f"Received request: {model_request.task}, {model_request.name}")
         if model_request.task not in (
             TaskType.IMAGE_GENERATION.value,
             TaskType.IMAGE_EMBEDDING.value,
             TaskType.TEXT_EMBEDDING.value,
             TaskType.OBJECT_DETECTION_2D.value,
             TaskType.IMAGE_SEGMENTATION_2D.value,
             TaskType.CUSTOM.value,
         ):
-            context.abort(grpc.StatusCode.NOT_FOUND, f"Invalid task [task={model_request.task}]")
+            context.abort(grpc.StatusCode.NOT_FOUND, f"Invalid task {model_request.task}")
 
         try:
             st = time.perf_counter()
-            logger.info(f"Executing request [task={model_request.task}, model={model_request.name}]")
+            logger.info(f"Executing request [task={model_request.task}, name={model_request.name}]")
             response = self.execute(model_request.name, task=TaskType(model_request.task), inputs=request.inputs)
             logger.info(
                 f"Executed request [task={model_request.task}, model={model_request.name}, elapsed={(time.perf_counter() - st) * 1e3:.1f}ms]"
             )
             return nos_service_pb2.InferenceResponse(response_bytes=dumps(response))
         except (grpc.RpcError, Exception) as e:
-            msg = f"Failed to execute request [task={model_request.task}, model={model_request.name}]"
+            msg = f"Failed to execute request: [task={model_request.task}, model={model_request.name}]"
             msg += f"{traceback.format_exc()}"
             logger.error(f"{msg}, e={e}")
             context.abort(grpc.StatusCode.INTERNAL, "Internal Server Error")
 
 
 def serve(address: str = f"[::]:{DEFAULT_GRPC_PORT}", max_workers: int = 1) -> None:
     """Start the gRPC server."""
```

## nos/test/conftest.py

```diff
@@ -140,40 +140,7 @@
     yield runtime
 
     # Tear down
     try:
         runtime.stop()
     except Exception:
         logger.info(f"Failed to stop existing container with name: {GPU_CONTAINER_NAME}")
-
-
-@pytest.fixture(scope="session")
-def local_grpc_client_with_server(grpc_server, grpc_client):  # noqa: F811
-    """Test local gRPC client with local runtime (Port: 50052)."""
-    # Wait for server to start
-    grpc_client.WaitForServer(timeout=180, retry_interval=5)
-    logger.info("Server started!")
-
-    # Yield the gRPC client once the server is up and initialized
-    yield grpc_client
-
-
-@pytest.fixture(scope="session")
-def grpc_client_with_cpu_backend(grpc_server_docker_runtime_cpu, grpc_client_cpu):  # noqa: F811
-    """Test gRPC client with initialized CPU docker runtime (Port: 50053)."""
-    # Wait for server to start
-    grpc_client_cpu.WaitForServer(timeout=180, retry_interval=5)
-    logger.info("Server started!")
-
-    # Yield the gRPC client once the server is up and initialized
-    yield grpc_client_cpu
-
-
-@pytest.fixture(scope="session")
-def grpc_client_with_gpu_backend(grpc_server_docker_runtime_gpu, grpc_client_gpu):  # noqa: F811
-    """Test gRPC client with initialized CPU docker runtime (Port: 50054)."""
-    # Wait for server to start
-    grpc_client_gpu.WaitForServer(timeout=180, retry_interval=5)
-    logger.info("Server started!")
-
-    # Yield the gRPC client once the server is up and initialized
-    yield grpc_client_gpu
```

## Comparing `autonomi_nos-0.0.7.dist-info/LICENSE` & `autonomi_nos-0.0.7a2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `autonomi_nos-0.0.7.dist-info/METADATA` & `autonomi_nos-0.0.7a2.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: autonomi-nos
-Version: 0.0.7
+Version: 0.0.7a2
 Summary: Nitrous oxide system (NOS) for computer-vision.
 License: MIT License
         
         Copyright (c) 2023 Autonomi AI
         
         Permission is hereby granted, free of charge, to any person obtaining a copy
         of this software and associated documentation files (the "Software"), to deal
```

## Comparing `autonomi_nos-0.0.7.dist-info/RECORD` & `autonomi_nos-0.0.7a2.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,67 +1,66 @@
 nos/__init__.py,sha256=hZuUzrXY9Px7KEt6deoV_-NKYiXLF_jtlQVA5hIPV0s,164
-nos/constants.py,sha256=9sddJLZSMR0sz4H7WvUgKBNvY8q5XSeioR0eBbRbzNE,637
+nos/constants.py,sha256=5uSx6pq0sLVVU-mBAuagfq-gEzpTRwSxrDV0aALW7qk,635
 nos/exceptions.py,sha256=ocRCxTbzT_Q8WTobAbkbo4jl5a6F3xC_D2N7rtzfWeg,93
 nos/logging.py,sha256=D0QDNFGmAYshfnSC-ctEDSIeBO6TnLPz1babUmJGRSA,940
-nos/protoc.py,sha256=LRCGTka1-ff-CeD8aoCqLFbDNn8MOGfxh-yS2MWmSHI,2897
-nos/version.py,sha256=R9xOYoYrWKcfO5zvTeGC3m_eDNOvxMd8CocQs2tLufo,22
+nos/protoc.py,sha256=xUck1U30UqUEnTaFuWMGWagyDcIrjmcQo8xozqbypmI,2778
+nos/version.py,sha256=wE0kuii8zMPGmvMf1N__Nkj1SPLydCz9UHFwb-9SV-s,24
 nos/cli/benchmark.py,sha256=k3ii0IyJ13rwziTqMUv9BxRP-iNX5p8bKb7tRJQqkcc,11371
 nos/cli/cli.py,sha256=DvLBCstXKrUY2DXeBKCfMxeN7sLd433AzPncyrbAxXo,540
 nos/cli/docker.py,sha256=VCAxJz33JKBsL7-Wq3Ui8creGiahR_chX0o5F8caOHs,4222
 nos/cli/hub.py,sha256=USdzVgaZlPZABrrIZzCA7ySwXg1iseEk7GJ7iwanXIg,1294
 nos/cli/predict.py,sha256=eo9Fc2ZmzaA6z1QenacKIYHMX4DYwCnIQHf3XTpyMho,7543
 nos/cli/serve_http.py,sha256=xMwSE46-_uHLgif1gnJCRoLbBE3ttC2zkm2JXVooWg0,5962
 nos/cli/system.py,sha256=wu4xrbQiVx7K1sTg07n5qeGrJ8q2NS_28k1a1J1sy4E,1706
 nos/cli/utils.py,sha256=uR1lGZyyDEuflNvxKuAmVUP-DTE55PzZL5c0c3l2h4U,425
 nos/client/__init__.py,sha256=oXG9pYr-XdtjExlDenSsleOzeCBzLGYIWwzD9-rkm6o,396
 nos/client/exceptions.py,sha256=76qw6r-5VYGm2HOXI6STgSo69dN7NpDHCWQeNvtedsw,351
-nos/client/grpc.py,sha256=2Omjv3HvLRfYERFCO_2wbqKA8jfztvxf1IQlOkSZjLQ,21230
-nos/common/__init__.py,sha256=vIaVY6sorQ5m9BdnO1XqIcouCZNn1cx_c9K0xs9WEiA,2257
+nos/client/grpc.py,sha256=BD4dHtohSIYm2H_lNWxn2b1CuSlQlnFnBQlhj4NMpuU,13192
+nos/common/__init__.py,sha256=I4hKyXjU0xs80tbzE4sjDLAiOCFUci67xBpYMkhsa4Y,1285
 nos/common/cloudpickle.py,sha256=2VBtGaLHbVtKg9ICT-xUITweHQCd6PxsFobDKwSYE2I,204
 nos/common/profiler.py,sha256=WrTJJZu3EeT630VfBwbHbz0vi3tDh4r0CakTe-kW8Jo,10364
-nos/common/shm.py,sha256=dNVAuKobbdnQrGL3-Ln1EvJYeqQC7bg155f20B4xnVA,11782
 nos/common/spec.py,sha256=_mcwc_OhflG19OwT5SkOtTsHDRuiceJKixOqf-HKI2g,9446
 nos/common/system.py,sha256=OpcOu91GsNbESiY6KADz4RRn9uk4xKLF0AtYbG3MvME,6076
-nos/common/tasks.py,sha256=eiF8vGOZangr7ulQRiwTGBnBJoVJLOlUGHlUfyDpxtY,569
+nos/common/tasks.py,sha256=4tpOPldlesiZTooo6RIZInhvxj818mp8h0Wyu_oMp20,593
 nos/common/types.py,sha256=MKNH-7qW8N1L-7nYH7b7NIgoSkt2JepcWxoLUvzX6QM,5984
 nos/common/io/__init__.py,sha256=NW8jGIcTResNmL7LeAlir6aHbFs6FU_n6no-2bdm2i8,1499
 nos/common/io/video/base.py,sha256=rAEBnj-LqkeqlCAXqGbAP49zKL3Q-m3sHhtLo6vh2ak,1050
 nos/common/io/video/opencv.py,sha256=s5CXfsbbk0IAXA42VvAFuaBO-d0nqaClZ2Qw7xU8taA,8424
 nos/compilers/__init__.py,sha256=viIY6XbOWebZnYFwKsgKxx9GbE5SXkn8alAjJbFTp_g,5832
 nos/compilers/trt/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 nos/compilers/trt/ops/group_norm.py,sha256=suIAbosSrDPMyKk_uuEhRPCggK73_wbE8YGSIMWanvk,2739
 nos/executors/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 nos/executors/ray.py,sha256=np0tmPRRRqVfO__ziKcYqPrZ_llLOSk_N8-BNXlzpOs,7544
 nos/hub/__init__.py,sha256=NWR3VWRshyMjw6LMLkK_aVs-00m4Gte7Ltf2UeD905c,3615
 nos/hub/config.py,sha256=DK0t6xrB6Sgf71YWnX_htNbbU4H2Bcdu9b7ujiA6QKY,2195
 nos/managers/__init__.py,sha256=ZLKQSo3Wj5B2fFyUiTTQlgQ97KWcpxJZtO27DseVbsU,59
-nos/managers/model.py,sha256=EJFoPeplnGURb9BgSUKkbsRJAUmtOOed9G7U5lCyiUA,7987
-nos/models/__init__.py,sha256=K8U1CBbwiUBLLkHQcCbEugyvce1HQWsvn1PckKHy1PQ,539
-nos/models/_noop.py,sha256=crVDEV_ll1gNTlrcC7sJGw9DcAOQImQ54hDBAT76bBw,922
+nos/managers/model.py,sha256=wNNCO90eQ2k5_0gDhqbE_UE8bnmJBp4cM3fi_c8qGzA,7911
+nos/models/__init__.py,sha256=7qIGd2FCQMyijmHRPgYW9uLG52hiBtGCOlTG0gT3C40,339
+nos/models/_noop.py,sha256=lH0FmIdG2xy-wvSZQP9BEEMjbRhAVtLUCa6RGUjZKCQ,879
 nos/models/clip.py,sha256=N2QB4gWVEHqfBKoSdvX2o2nX9_9TCE7MySGRIj49IQA,9931
 nos/models/faster_rcnn.py,sha256=7cy83dKT4Nfj6sEFA2Xzc3XMXzgYbIcgaKlqaBDR_yQ,2834
 nos/models/sam.py,sha256=bMGxM9unwmCA9TfHOI9IFwW5iLlOwxbO7OmcBCtLNJg,1507
 nos/models/stable_diffusion.py,sha256=oCXjjwlMXssLS3f7-voN-2Sj-84fyW62-KEu7U1ZgJc,16095
 nos/models/yolox.py,sha256=wuOkm6jCmNLgZyu2Uad2WnW_YKlqqqYx7R19_nBGpGs,10128
 nos/models/openmmlab/__init__.py,sha256=VzlwVzMv9EVqdyKwvTDBaVhH9RYnYv0zEU_v4wEdR4w,63
 nos/models/openmmlab/mmdetection/mmdetection.py,sha256=gjWBD3t4CXEFd5t-k_qBHbk_Hi588nn-YGll68jM4Eo,3066
 nos/models/openmmlab/mmdetection/configs/_base_/default_runtime.py,sha256=tAbybUUg9TtBy_dqiXD5Zgl0kSs39JX7TiTeIYZrOUo,370
 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_detection.py,sha256=MxNi_Sf1m8CNkR64vZWaFN2O2P2LBI1-EexpLr166YU,3187
 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_instance.py,sha256=DVkj2zskGrXxiF6hVQ1ofsOsqQGHsdjAh5sXRkaxjiw,1765
 nos/models/openmmlab/mmdetection/configs/_base_/models/faster-rcnn_r50_fpn.py,sha256=Al2qpY2P-MzsfBCod5pjB6HrH7ZzFvQxICc1CVmpnRY,3828
 nos/models/openmmlab/mmdetection/configs/_base_/schedules/schedule_1x.py,sha256=G8gXisLhM7mBRlxrhTOLCsWD17zCyH7kBvVi7J4BICI,304
 nos/models/openmmlab/mmdetection/configs/efficientdet/efficientdet_effb3_bifpn_8xb16-crop896-300e_coco.py,sha256=RSkd9o1IO-YkWhIwnXU83tRyGeySiR1IMlSk14dTw9s,5340
 nos/models/openmmlab/mmdetection/configs/faster-rcnn/faster-rcnn_r50_fpn_1x_coco.py,sha256=Cm8lyQ3wOT5I9KR0m1TfTsPAGybs-buILRPLDZKzOPQ,177
-nos/proto/nos_service.proto,sha256=QosZqAWguTYpvxc_abJKc7_ynhdhfZusQsXA45sHmkk,2850
-nos/server/__init__.py,sha256=A39yTNnduh92nFVaamxLPEOPApyoJXzj9eq62DRdqQk,10206
-nos/server/_docker.py,sha256=gL1n5ObJp2Uce5XKt9duW9ng7C9J-ey6FXIiXxkyGSE,6724
-nos/server/_runtime.py,sha256=ea6bF-7bn1eLdrTPz3QOH0yz4qe-ACm2KovwhqVxzKA,6766
-nos/server/_service.py,sha256=xC6uHMhUp2yb0O0FoIJeowVke5WZlRrDrOylyHCeQLY,11883
+nos/proto/nos_service.proto,sha256=BEWdRsehHLaSjH2K2QEhtmaDqkwDZYdxKm1t4yg_0V8,2437
+nos/server/__init__.py,sha256=x6EzKKWVhc_FsqwtdAARS6uswVZCqUFemEv7wt1M7PU,10198
+nos/server/_docker.py,sha256=Hrq40bwFPejA2k0fX8MooTwsYbrAoped8Uk7KAOWwfU,6725
+nos/server/_runtime.py,sha256=ppYsFHoXqiIU0nJzFPlknXon1GO13WxCoY_idkgCfnw,6482
+nos/server/_service.py,sha256=aEqML7qaYJ5rcyf4KBStklwshg-7-Sra9G9vtx3EZJI,7989
 nos/test/benchmark.py,sha256=b_QMHfStY5iRjHGPZwaY7VrXzy_VeFKfjld9UEVbn-g,373
-nos/test/conftest.py,sha256=R8ZkXyVbRK0sLRTynpE9j5a5wimZzk-IqgYSIxE9VcM,5498
+nos/test/conftest.py,sha256=20YuaBtHaMNUDEkvuHFl32J4jX5zpHGc-jTcvPHo4bk,4237
 nos/test/utils.py,sha256=bi-aoXsTmDiwmwlWVyhznW_ZS7k7N9bZJuq-QuMz2OA,2626
-autonomi_nos-0.0.7.dist-info/LICENSE,sha256=9TQFxQ2AkXOQuIHy9GueB_a18hayRXT7pDt9fJv9WLo,1068
-autonomi_nos-0.0.7.dist-info/METADATA,sha256=KbenbEXZp9YwyqTqXcYSOhROMhzuWftMJ_sNXLWusNM,6798
-autonomi_nos-0.0.7.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-autonomi_nos-0.0.7.dist-info/entry_points.txt,sha256=KcZyneDX7Iv7PMPuohaLfe2xQMUVnE7S2apsS5aIshA,87
-autonomi_nos-0.0.7.dist-info/top_level.txt,sha256=RgOntmzdTkyrY-Fj9H6bSke7af3bHLscoZnK1-7Aa8o,12
-autonomi_nos-0.0.7.dist-info/RECORD,,
+autonomi_nos-0.0.7a2.dist-info/LICENSE,sha256=9TQFxQ2AkXOQuIHy9GueB_a18hayRXT7pDt9fJv9WLo,1068
+autonomi_nos-0.0.7a2.dist-info/METADATA,sha256=nSFaGXKg3oTB80yk2BO3U2_7yjP7JpdOk5nJOpp-HDo,6800
+autonomi_nos-0.0.7a2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+autonomi_nos-0.0.7a2.dist-info/entry_points.txt,sha256=KcZyneDX7Iv7PMPuohaLfe2xQMUVnE7S2apsS5aIshA,87
+autonomi_nos-0.0.7a2.dist-info/top_level.txt,sha256=RgOntmzdTkyrY-Fj9H6bSke7af3bHLscoZnK1-7Aa8o,12
+autonomi_nos-0.0.7a2.dist-info/RECORD,,
```

